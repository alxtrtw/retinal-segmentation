{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"eye_retina.ipynb","provenance":[],"authorship_tag":"ABX9TyOTUbxHu/1k7dJ4i05TqUuy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import argparse\n","from glob import glob\n","\n","import numpy as np\n","from PIL import Image\n","from keras import backend as K\n","from keras import losses\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from keras.layers import Input, MaxPooling2D\n","from keras.layers import concatenate, Conv2D, Conv2DTranspose, Dropout, ReLU\n","from keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from numpy import random\n","import tensorflow as tf\n","from random import randint\n","\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"wgbojG9Wcu_6","executionInfo":{"status":"ok","timestamp":1650439103423,"user_tz":-120,"elapsed":236,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import keras\n","from keras_preprocessing import image\n","from PIL import Image\n","import cv2\n","\n","\n","def random_flip(img, mask, u=0.5):\n","    if np.random.random() < u:\n","        img = image.flip_axis(img, 1)\n","        mask = image.flip_axis(mask, 1)\n","    if np.random.random() < u:\n","        img = image.flip_axis(img, 0)\n","        mask = image.flip_axis(mask, 0)\n","    return img, mask\n","\n","def random_rotate(img, mask, rotate_limit=(-20, 20), u=0.5):\n","    if np.random.random() < u:\n","        theta = np.random.uniform(rotate_limit[0], rotate_limit[1])\n","        img = image.apply_affine_transform(img, theta=theta)\n","        mask = image.apply_affine_transform(mask, theta=theta)\n","    return img, mask\n","\n","def shift(x, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n","    h, w = x.shape[row_axis], x.shape[col_axis]\n","    tx = hshift * h\n","    ty = wshift * w\n","    x = image.apply_affine_transform(x, ty=ty, tx=tx)\n","    return x\n","\n","def random_shift(img, mask, w_limit=(-0.1, 0.1), h_limit=(-0.1, 0.1), u=0.5):\n","    if np.random.random() < u:\n","        wshift = np.random.uniform(w_limit[0], w_limit[1])\n","        hshift = np.random.uniform(h_limit[0], h_limit[1])\n","        img = shift(img, wshift, hshift)\n","        mask = shift(mask, wshift, hshift)\n","    return img, mask\n","\n","def random_zoom(img, mask, zoom_range=(0.8, 1), u=0.5):\n","    if np.random.random() < u:\n","        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n","        img = image.apply_affine_transform(img, zx=zx, zy=zy)\n","        mask = image.apply_affine_transform(mask, zx=zx, zy=zy)\n","    return img, mask\n","\n","\n","\n","def random_shear(img, mask, intensity_range=(-0.5, 0.5), u=0.5):\n","    if np.random.random() < u:\n","        sh = np.random.uniform(-intensity_range[0], intensity_range[1])\n","        img = image.apply_affine_transform(img, shear=sh)\n","        mask = image.apply_affine_transform(mask, shear=sh)\n","    return img, mask\n","\n","def random_gray(img, u=0.5):\n","    if np.random.random() < u:\n","        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n","        gray = np.sum(img * coef, axis=2)\n","        img = np.dstack((gray, gray, gray))\n","    return img\n","\n","def random_contrast(img, limit=(-0.3, 0.3), u=0.5):\n","    if np.random.random() < u:\n","        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n","        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n","        gray = img * coef\n","        gray = (3.0 * (1.0 - alpha) / gray.size) * np.sum(gray)\n","        img = alpha * img + gray\n","        img = np.clip(img, 0., 1.)\n","    return img\n","\n","def random_brightness(img, limit=(-0.3, 0.3), u=0.5):\n","    if np.random.random() < u:\n","        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n","        img = alpha * img\n","        img = np.clip(img, 0., 1.)\n","    return img\n","\n","def random_saturation(img, limit=(-0.3, 0.3), u=0.5):\n","    if np.random.random() < u:\n","        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n","        coef = np.array([[[0.114, 0.587, 0.299]]])\n","        gray = img * coef\n","        gray = np.sum(gray, axis=2, keepdims=True)\n","        img = alpha * img + (1. - alpha) * gray\n","        img = np.clip(img, 0., 1.)\n","    return img\n","\n","def random_channel_shift(x, limit, channel_axis=2):\n","    x = np.rollaxis(x, channel_axis, 0)\n","    min_x, max_x = np.min(x), np.max(x)\n","    channel_images = [np.clip(x_ch + np.random.uniform(-limit, limit), min_x, max_x) for x_ch in x]\n","    x = np.stack(channel_images, axis=0)\n","    x = np.rollaxis(x, 0, channel_axis + 1)\n","    return x\n","\n","def random_crop(img, mask, u=0.1):\n","    if np.random.random() < u:\n","        w, h = img.shape[0], img.shape[1]\n","        offsetw = np.random.randint(w//2)\n","        offseth = np.random.randint(w//2)\n","\n","        endw = np.random.randint(w // 2)+w // 2\n","        endh = np.random.randint(w // 2)+w // 2\n","\n","        new_im = img[offsetw:offsetw + endw, offseth:offseth + endh, :]\n","        new_mask = mask[offsetw:offsetw + endw, offseth:offseth + endh, :]\n","\n","        new_im, new_mask = cv2.resize(new_im, interpolation = cv2.INTER_LINEAR, dsize=(w, h)), \\\n","               cv2.resize(new_mask, interpolation=cv2.INTER_LINEAR, dsize=(w, h))\n","\n","        new_mask = new_mask[..., np.newaxis]\n","        return new_im, new_mask\n","    else:\n","        return img, mask\n","\n","\n","def random_augmentation(img, mask):\n","    img = random_brightness(img, limit=(-0.1, 0.1), u=0.05)\n","    img = random_contrast(img, limit=(-0.1, 0.1), u=0.05)\n","    img = random_saturation(img, limit=(-0.1, 0.1), u=0.05)\n","    img, mask = random_rotate(img, mask, rotate_limit=(-10, 10), u=0.05)\n","    img, mask = random_shear(img, mask, intensity_range=(-5, 5), u=0.05)\n","    img, mask = random_flip(img, mask, u=0.5)\n","    img, mask = random_shift(img, mask, w_limit=(-0.1, 0.1), h_limit=(-0.1, 0.1), u=0.05)\n","    img, mask = random_zoom(img, mask, zoom_range=(0.9, 1.1), u=0.05)\n","    return img, mask"],"metadata":{"id":"o_9Ozy1oe0Bz","executionInfo":{"status":"ok","timestamp":1650436831683,"user_tz":-120,"elapsed":819,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7p5t91uRjBzg","executionInfo":{"status":"ok","timestamp":1650436832044,"user_tz":-120,"elapsed":366,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}}},"outputs":[],"source":["\n","\n","batch_size = 16\n","input_shape = (64, 64)\n","\n","\n","def custom_activation(x):\n","    return K.relu(x, alpha=0.0, max_value=1)\n","\n","\n","def focal_loss(gamma=2., alpha=.25):\n","    def focal_loss_fixed(y_true, y_pred):\n","        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n","        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n","        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n","    return focal_loss_fixed\n","\n","smooth = 1.\n","\n","\n","\n","def get_unet(do=0, activation=ReLU):\n","    inputs = Input((None, None, 3))\n","    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(inputs)))\n","    conv1 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv1)))\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(pool1)))\n","    conv2 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv2)))\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(pool2)))\n","    conv3 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv3)))\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(pool3)))\n","    conv4 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv4)))\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(pool4)))\n","    conv5 = Dropout(do)(activation()(Conv2D(512, (3, 3), padding='same')(conv5)))\n","\n","    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n","    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(up6)))\n","    conv6 = Dropout(do)(activation()(Conv2D(256, (3, 3), padding='same')(conv6)))\n","\n","    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n","    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(up7)))\n","    conv7 = Dropout(do)(activation()(Conv2D(128, (3, 3), padding='same')(conv7)))\n","\n","    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n","    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(up8)))\n","    conv8 = Dropout(do)(activation()(Conv2D(64, (3, 3), padding='same')(conv8)))\n","\n","    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n","    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(up9)))\n","    conv9 = Dropout(do)(activation()(Conv2D(32, (3, 3), padding='same')(conv9)))\n","\n","    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","\n","    model = Model(inputs=[inputs], outputs=[conv10])\n","\n","    model.compile(optimizer=Adam(lr=1e-3), loss=losses.binary_crossentropy, metrics=['accuracy'])\n","\n","\n","    return model\n","\n","\n","def read_input(path):\n","    x = np.array(Image.open(path))/255.\n","    return x\n","\n","\n","def read_gt(path):\n","    x = np.array(Image.open(path))/255.\n","    return x[..., np.newaxis]\n","\n","\n","def random_crop(img, mask, crop_size=input_shape[0]):\n","    imgheight= img.shape[0]\n","    imgwidth = img.shape[1]\n","    i = randint(0, imgheight-crop_size)\n","    j = randint(0, imgwidth-crop_size)\n","\n","    return img[i:(i+crop_size), j:(j+crop_size), :], mask[i:(i+crop_size), j:(j+crop_size)]\n"]},{"cell_type":"code","source":["def gen(data, au=False):\n","    while True:\n","        repeat = 4\n","        index= random.choice(list(range(len(data))), batch_size//repeat)\n","        index = list(map(int, index))\n","        list_images_base = [read_input(data[i][0]) for i in index]\n","        list_gt_base = [read_gt(data[i][1]) for i in index]\n","\n","        list_images = []\n","        list_gt = []\n","\n","        for image, gt in zip(list_images_base, list_gt_base):\n","\n","            for _ in range(repeat):\n","                image_, gt_ = random_crop(image.copy(), gt.copy())\n","                list_images.append(image_)\n","                list_gt.append(gt_)\n","\n","        list_images_aug = []\n","        list_gt_aug = []\n","\n","        for image, gt in zip(list_images, list_gt):\n","            if au:\n","                image, gt = random_augmentation(image, gt)\n","            list_images_aug.append(image)\n","            list_gt_aug.append(gt)\n","\n","        yield np.array(list_images_aug), np.array(list_gt_aug)"],"metadata":{"id":"VJAC2G_tc0hV","executionInfo":{"status":"ok","timestamp":1650436832045,"user_tz":-120,"elapsed":6,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model_name = \"model_1\"\n","\n","train_data = list(zip(sorted(glob('../content/img/*.ppm')),\n","                      sorted(glob('../content/target/*.ppm'))))\n","\n","model = get_unet(do=0.1, activation=ReLU)\n","\n","file_path = model_name + \"weights.best.hdf5\"\n","try:\n","    model.load_weights(file_path, by_name=True)\n","except:\n","    pass\n","\n","\n","\n","\n","history = model.fit_generator(gen(train_data, au=True), epochs=5, verbose=2,\n","                      steps_per_epoch= 100*len(train_data)//batch_size,\n","                              use_multiprocessing=True, workers=16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFti0IvtjtWO","executionInfo":{"status":"ok","timestamp":1650438588722,"user_tz":-120,"elapsed":1525714,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}},"outputId":"1b082744-03fb-427e-e46a-f9817a88455b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","125/125 - 295s - loss: 0.3763 - accuracy: 0.8908 - 295s/epoch - 2s/step\n","Epoch 2/5\n","125/125 - 286s - loss: 0.2646 - accuracy: 0.9066 - 286s/epoch - 2s/step\n","Epoch 3/5\n","125/125 - 295s - loss: 0.2647 - accuracy: 0.9049 - 295s/epoch - 2s/step\n","Epoch 4/5\n","125/125 - 292s - loss: 0.2520 - accuracy: 0.9106 - 292s/epoch - 2s/step\n","Epoch 5/5\n","125/125 - 298s - loss: 0.1934 - accuracy: 0.9276 - 298s/epoch - 2s/step\n"]}]},{"cell_type":"code","source":[" model.save_weights(file_path)"],"metadata":{"id":"5YbkPIadtk0m","executionInfo":{"status":"ok","timestamp":1650438966080,"user_tz":-120,"elapsed":5,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["read_input('../content/img/im0009.ppm').shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"id":"i8fbIZ402Bqh","executionInfo":{"status":"error","timestamp":1650439348745,"user_tz":-120,"elapsed":271,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}},"outputId":"06646849-b104-4742-c8e2-f02d7c71d405"},"execution_count":32,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-110d7f781b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../content/img/im0009.ppm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-451ead8ff460>\u001b[0m in \u001b[0;36mread_input\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../content/img/im0009.ppm'"]}]},{"cell_type":"code","source":["prediction = model.predict_generator(read_input('../content/img/im0001.ppm'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":764},"id":"6f3JFEXap3rf","executionInfo":{"status":"error","timestamp":1650439216020,"user_tz":-120,"elapsed":353,"user":{"displayName":"Alex Terentowicz","userId":"10722644937446686009"}},"outputId":"46edc9e3-43e2-4649-be7a-4df2c1467f81"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Model was constructed with shape (None, None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 700, 3).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-b578fe985a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../content/img/im0001.ppm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2281\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2283\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   2284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2285\u001b[0m   \u001b[0;31m######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_1\" (type Functional).\n    \n    Input 0 of layer \"conv2d_19\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 700, 3)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 700, 3), dtype=float32)\n      • training=False\n      • mask=None\n"]}]}]}